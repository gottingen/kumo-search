服务发现
=====================

服务发现是个老生常谈的话题，但是在微服务架构中，服务发现的重要性更加凸显。 在微服务架构中，服务的数量会迅速增加，服务的实例也会频繁变化，
因此需要一个服务发现机制来帮助服务之间相互发现和调用。基础的概念也不再赘述，需要了解的可以参考[维基百科][1]。

简单描述下服务发现， 从角色维度服务提供者、服务消费者、服务注册中心，从功能维度服务注册、服务发现、服务监控。我们从服务发现的角度来看待服务发现系统。

* 服务提供者：服务提供者是服务的生产者，提供服务的实例，需要将自己的服务注册到服务发现系统中。
* 服务消费者：服务消费者是服务的消费者，需要从服务发现系统中获取服务的实例信息，然后调用服务。
* 服务注册中心：服务注册中心是服务发现系统的核心，负责服务的注册、发现、监控等功能。

结合设计场景，针对服务发现系统总结了以下几点需求：

* 接口语言： 同时兼顾多语言支持，提供简单易用的API接口。
* 部署：    部署简单，简单到可以一键部署。
* 运维成本： 运维成本低，接近或者自动化运维。
* 隐性条件： 系统逻辑简单，无使用者心智负担。比如一些隐性条件，不体现在API接口上，但是会影响接口结果。
* 高可用：  高可用，服务发现系统是整个微服务架构的核心，必须保证高可用。

# 服务发现系统对比

在开始设计服务发现系统之前，我们先对比一下几个开源的服务发现系统，以便更好的选择合适的服务发现系统。如果有项目可以直接使用，那么就不需要重复造轮子。

## bns

bns是百度内部使用的服务发现系统，提供了服务注册、发现、监控等功能。bns是百度内部的服务发现系统，不对外开放，所以不考虑。

## etcd

etcd是一个分布式键值存储系统，提供了服务注册、发现、配置管理等功能。etcd是一个开源项目，可以业界使用也很广泛，性能和稳定性都能得到验证。`etcd`是
go语言开发的项目，外部依赖少，部署简单，支持多语言客户端，可以满足多语言支持的需求。`etcd`的缺点是运维成本较高，需要专门的运维人员进行维护。

## consul

与`etcd`类似，`consul`也是一个分布式键值存储系统，提供了服务注册、发现、配置管理等功能。`consul`是go语言开发的项目，外部依赖少，部署简单，支持多语言客户端，
可以满足多语言支持的需求。`consul`的缺点也是运维成本较高，需要专门的运维人员进行维护。

## zookeeper

`zookeeper`是一个分布式协调服务，早年间被广泛应用于服务发现系统。`zookeeper`是java语言开发的项目，性能和稳定性都能得到验证。`zookeeper`的缺点是运维成本较高，
需要专门的运维人员进行维护， 同时，性能也不如`etcd`和`consul`。

## nacos

`nacos`是阿里巴巴开源的服务发现系统，提供了服务注册、发现、配置管理等功能。`nacos`是java语言开发的项目，性能和稳定性都能得到验证。`nacos`的优点是运维成本比较高。
`nacos`的作为企业内部的服务发现系统，功能比较全面，支持多语言客户端，可以满足多语言支持的需求。同时带来的问题是运维成本较高，需要专门的运维人员进行维护。

## discovery

`discovery`是一个轻量级的服务发现系统，提供了服务注册、发现、监控等功能。`discovery`是go语言开发的项目，外部依赖少，部署简单，支持多语言客户端，可以满足多语言支持的需求。
`discovery`的优点是运维成本低，接近或者自动化运维。`discovery`同时支持多数据中心，可以满足多数据中心的需求。`discovery`的缺点是功能相对简单，不支持配置管理等功能。

## 其他系统

除了上面几个系统，还有一些其他的服务发现系统，如`eureka`、`skywalking`等，这些系统都是比较成熟的服务发现系统，可以根据实际需求选择合适的服务发现系统。但是考虑到运维成本，
放弃了这些系统。我们最终的会在`go`与`c++`语言开发的系统重选择实现一个轻量级的服务发现系统。

# 服务发现系统设计

回到我们服务发现服务，整合需求：

* 服务器规模 - 我们的服务发现服务不需要大量的服务管理，管理的服务器在百台级别，服务在千级别。
* 权限管理  - 团队内部使用，不需要权限管理。
* 接口语言： 同时兼顾多语言支持，提供简单易用的API接口。
* 部署：    部署简单，简单到可以一键部署。
* 运维成本： 运维成本低，接近或者自动化运维。
* 隐性条件： 系统逻辑简单，无使用者心智负担。比如一些隐性条件，不体现在API接口上，但是会影响接口结果。
* 高可用：  高可用，服务发现系统是整个微服务架构的核心，必须保证高可用。
* 自动剔除坏节点 - 服务发现系统需要自动剔除坏节点，保证服务的可用性。

化繁为简，以上的系统，discovery系统是最符合我们的需求的。我们选择`discovery`系统作为我们的服务发现系统。

# 设计能满足生产环境吗？

理论上，服务发现系统还要包括服务服务降级、迁移、熔断、限流，甚至包括trace等功能。实际多数企业内，连服务发现这个系统都没有，更别说服务降级、迁移、熔断、限流等功能了。
很多服务都是通过配置文件来配置服务的地址，来调用服务，特别是运行年代比较久的企业，很多服务都是这样调用。并非服务发现的功能有多大技术瓶颈，而是这种服务的历史包袱太重，
很难改变。所以，服务发现系统的设计，要根据实际情况来，不要过度设计，不要过度追求完美，要根据实际情况来。

从另一个维度-开发设计的角度来看，服务发现系统的设计，要尽量简单，不要过度设计，不要过度追求完美，要根据实际情况来。服务发现系统的设计。

很多企业内部使用的是诸如 `redis`、`mysql`等软件做一层二次开发，来实现服务发现的功能。这种方式虽然不够完美，但是实现简单，运维成本低，可以满足基本的需求。

还有一定是我们计较关注，关于服务的稳定性，如果业务的服务出现故障，能够快速迁移或者剔除坏节点，根据我们的经验，一个服务集群，同时出现故障的概率是很低的，所以我们
不需要过度设计这个功能，能够保证服务down掉后，能够快速剔除坏节点即可。这点在melon中已经实现。

# 服务发现系统的设计

[1]: https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0